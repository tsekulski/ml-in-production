{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing machine learning models for real-time scoring in production environment\n",
    "### Real-time scoring considerations\n",
    "* How can I check incoming raw data quality on the fly?\n",
    "* How can I ensure that broken data won't break my model / API?\n",
    "* How can I perform feature engineering on the fly?\n",
    "### What are sklearn pipelines? How can they help solve above challenges?\n",
    "### How can I create a pipeline?\n",
    "### How can I write my own data preprocessors and embed them in a sklearn pipeline? [Highlight]\n",
    "### [Optional] Time-based train-test split and final production-ready model training\n",
    "### [Optional] Using Flask and Docker to embed your model in a production-ready REST API\n",
    "### [Optional] Latency testing with Locust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "# PART 0\n",
    "## LOADING NECESSARY SOFTWARE PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Load necessary packages\n",
    "print('Loading standard Python packages...')\n",
    "\n",
    "# General, data handling and visualization\n",
    "import platform\n",
    "import os\n",
    "import sys\n",
    "from shutil import copyfile, copytree, rmtree\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "# Data preprocessing, ML model training & validation\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn.externals import joblib # to save models\n",
    "\n",
    "# Probability calibration\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "# Pipelining\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # for definition of custom transformers\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Datetime conversions\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "import bisect\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# Set jupyter screen width to 100%\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "print('Standard Python packages successfully loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check package versions\n",
    "print('Your system type and version of key dependencies:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Operating system:', platform.system())\n",
    "print('OS release:', platform.release())\n",
    "print('Machine:', platform.machine())\n",
    "print('Platform:', platform.platform())\n",
    "print('Version:', platform.version())\n",
    "print()\n",
    "print('Python version: {}'.format(sys.version))\n",
    "print('Pandas version: {}'.format(pd.__version__))\n",
    "print('Numpy version: {}'.format(np.__version__))\n",
    "print('Scikit-learn version: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load helper functions\n",
    "print('Importing custom helper functions...')\n",
    "\n",
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "from src.library.helper_functions import predict, validate, plot_ROC_curve, plot_precision_recall_curve\n",
    "\n",
    "print('Helper functions imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load widget class that allows the user to browse for the data file to be used\n",
    "#print('Importing custom FileBrowser widget...')\n",
    "\n",
    "#from src.library.select_file import FileBrowser \n",
    "\n",
    "#print('FileBrowser widget imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load custom preprocessing transformers - to be used in the pipeline later on\n",
    "print('Importing custom data preprocessors...')\n",
    "\n",
    "from src.library.pipeline_components import WhitespaceRemover, CastToOriginalDtypes, CastToUserDtypes, CheckForUnseenValues, DfToDict\n",
    "from src.library.pipeline_components import IntegerEncoder, DayOfWeekEncoder, DeviceEncoder, FeatureRemover, AgeEncoder\n",
    "\n",
    "print('Custom preprocessors imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up the training & prediction pipeline\n",
    "\n",
    "print('Setting up model training and prediction pipelines...')\n",
    "\n",
    "# Create random forest classifier object\n",
    "RF_clf = RandomForestClassifier(n_estimators=100, # different than default, default = 10\n",
    "                                criterion='gini',\n",
    "                                max_depth=None, # Changed to 100 to limit the depth of each tree..\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                max_features=1, # different than default, default = 'auto'\n",
    "                                max_leaf_nodes=None,\n",
    "                                bootstrap=True,\n",
    "                                oob_score=False,\n",
    "                                n_jobs=-1, # use all available cores\n",
    "                                random_state=0, # define random state for reproducibility of results\n",
    "                                verbose=0,\n",
    "                                warm_start=False,\n",
    "                                class_weight=None)\n",
    "\n",
    "## Create pipeline - no calibration\n",
    "RF_pipeline_uncalibrated = Pipeline([('whitespaceremoval', WhitespaceRemover()),\n",
    "                                    ('originaldtypescasting', CastToOriginalDtypes()),\n",
    "                                    ('deviceencoder', DeviceEncoder()),\n",
    "                                    ('ageencoder', AgeEncoder()),\n",
    "                                    ('dayofweekencoder', DayOfWeekEncoder()),\n",
    "                                    ('userdtypescasting', CastToUserDtypes()),\n",
    "                                    ('unseenvalueschecker', CheckForUnseenValues()),\n",
    "                                    ('featureremoval', FeatureRemover()),\n",
    "                                    ('dicttransformer', DfToDict()),\n",
    "                                    ('ohe', DictVectorizer()),\n",
    "                                    ('imputation', Imputer(missing_values='NaN', strategy='most_frequent')),\n",
    "                                    ('scaling', StandardScaler(with_mean=False)),\n",
    "                                    ('classifier', RF_clf)])\n",
    "\n",
    "## Isotonic calibration\n",
    "RF_pipeline_isotonic = Pipeline([('whitespaceremoval', WhitespaceRemover()),\n",
    "                                    ('originaldtypescasting', CastToOriginalDtypes()),\n",
    "                                    ('deviceencoder', DeviceEncoder()),\n",
    "                                    ('ageencoder', AgeEncoder()),\n",
    "                                    ('dayofweekencoder', DayOfWeekEncoder()),\n",
    "                                    ('userdtypescasting', CastToUserDtypes()),\n",
    "                                    ('unseenvalueschecker', CheckForUnseenValues()),\n",
    "                                    ('featureremoval', FeatureRemover()),\n",
    "                                    ('dicttransformer', DfToDict()),\n",
    "                                    ('ohe', DictVectorizer()),\n",
    "                                    ('imputation', Imputer(missing_values='NaN', strategy='most_frequent')),\n",
    "                                    ('scaling', StandardScaler(with_mean=False)),\n",
    "                                    #('classifier', RF_clf)])\n",
    "                                    ('classifier', CalibratedClassifierCV(base_estimator=RF_clf, cv=2, method='isotonic'))])\n",
    "\n",
    "## Sigmoid calibration\n",
    "RF_pipeline_sigmoid = Pipeline([('whitespaceremoval', WhitespaceRemover()),\n",
    "                                    ('originaldtypescasting', CastToOriginalDtypes()),\n",
    "                                    ('deviceencoder', DeviceEncoder()),\n",
    "                                    ('ageencoder', AgeEncoder()),\n",
    "                                    ('dayofweekencoder', DayOfWeekEncoder()),\n",
    "                                    ('userdtypescasting', CastToUserDtypes()),\n",
    "                                    ('unseenvalueschecker', CheckForUnseenValues()),\n",
    "                                    ('featureremoval', FeatureRemover()),\n",
    "                                    ('dicttransformer', DfToDict()),\n",
    "                                    ('ohe', DictVectorizer()),\n",
    "                                    ('imputation', Imputer(missing_values='NaN', strategy='most_frequent')),\n",
    "                                    ('scaling', StandardScaler(with_mean=False)),\n",
    "                                    #('classifier', RF_clf)])\n",
    "                                    ('classifier', CalibratedClassifierCV(base_estimator=RF_clf, cv=2, method='sigmoid'))])\n",
    "                                \n",
    "\n",
    "print('Model training and prediction pipelines set up.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "# PART 1\n",
    "## LET'S HAVE A LOOK AT THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using a modified open-source German credit scoring dataset\n",
    "Original dataset is available under https://www.kaggle.com/uciml/german-credit/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Please select the data file that should be used for model training:')\n",
    "#datafile = FileBrowser()\n",
    "#datafile.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load ORIGINAL full TMA dataset\n",
    "print('Reading in selected file...')\n",
    "# Uncomment the below read_csv statement to load a test sample of the data, for a test run of the notebook\n",
    "#df = pd.read_csv('../data/interim/np_training_2_downsampled.csv',\n",
    "#                 parse_dates=['PURCHASE_DATE', 'BIRTHDATE'],\n",
    "#                 low_memory=False)\n",
    "\n",
    "# Uncomment the below read_csv statement to load the full TMA dataset\n",
    "df = pd.read_csv('../data/kaggle_german_credit_data_original_with_label.csv',\n",
    "                 #sep='\\t',\n",
    "                 #decimal=',',\n",
    "                 #parse_dates=['PURCHASE_DATE', 'BIRTHDATE'],\n",
    "                 #encoding='ISO-8859-1',\n",
    "                 low_memory=False)\n",
    "\n",
    "print('File successfully read in. Analyzing...')\n",
    "\n",
    "print('Table dimensions:')\n",
    "print('Number of rows:', df.shape[0])\n",
    "print('Number of columns:', df.shape[1])\n",
    "print()\n",
    "pd.set_option(\"display.max_columns\", df.shape[1])\n",
    "pd.set_option(\"display.max_rows\", df.shape[1])\n",
    "print('Overview of the first five table rows:')\n",
    "display(df.head())\n",
    "print('Overview of the last five table rows:')\n",
    "display(df.head())\n",
    "# print('Column datatypes:')\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='Risk', data=df)\n",
    "plt.show()\n",
    "display(df['Risk'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df['Gender'] = df['Sex']\n",
    "df.drop(['Sex'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Purchase_date'] = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_dates(start, end, n=1):\n",
    "\n",
    "    start_u = start.value//10**9\n",
    "    end_u = end.value//10**9\n",
    "\n",
    "    return pd.to_datetime(np.random.randint(start_u, end_u, n), unit='s').date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2020-01-01')\n",
    "end_date = pd.to_datetime('2020-05-15')\n",
    "random_dates(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Purchase_date'] = df.apply(lambda row : random_dates(start_date, end_date), axis=1)\n",
    "df['Purchase_date'] = pd.to_datetime(df['Purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_birth_date(row):\n",
    "    purchase_date = row['Purchase_date']\n",
    "    age_years = row['Age']\n",
    "    \n",
    "    return purchase_date - pd.DateOffset(years=age_years)\n",
    "\n",
    "df['Birth_date'] = df.apply(lambda row : generate_birth_date(row), axis=1)\n",
    "df['Birth_date'] = pd.to_datetime(df['Birth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def allocate_device(device_lst):\n",
    "    return random.choice(device_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_list = [\n",
    "    'iPhone 10 Black',\n",
    "    'iPhone 11 Black',\n",
    "    'iPhone 10 White',\n",
    "    'iPhone 11 Black',\n",
    "    'iPhone 9',\n",
    "    'Samsung Amazing',\n",
    "    'Huawei Great',\n",
    "    'Nokia Old',\n",
    "    'Samsung Fantastic',\n",
    "    'Huawei Fantastic',\n",
    "    'Samsung Awesome',\n",
    "    'Huawei Awesome'\n",
    "]\n",
    "\n",
    "df['Device'] = df.apply(lambda row : allocate_device(device_list), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime(df['BIRTHDATE'].replace('nan', np.nan))\n",
    "#df['BIRTHDATE'].sort_values(ascending=False).replace('nan', np.nan).head(14270)\n",
    "#df.loc[df['BIRTHDATE'] == '01.07.50']\n",
    "\n",
    "#for index, row in df.iterrows():\n",
    "#    try:\n",
    "#        pd.to_datetime(row['BIRTHDATE'])\n",
    "#    except:\n",
    "#        print(index)\n",
    "#        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import resample\n",
    "#df_downsampled = resample(df, n_samples=10000, replace=False, random_state=0)\n",
    "#df_downsampled.to_csv('../data/interim/np_training_2_downsampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1\n",
    "### Check for and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "# Select duplicate rows except first occurrence based on all columns\n",
    "\n",
    "print('Checking for duplicates...')\n",
    "duplicateRowsDF = df[df.duplicated()]\n",
    "if duplicateRowsDF.shape[0] == 0:\n",
    "    print(\"Good news - no duplicates found.\")\n",
    "else:\n",
    "    print('Duplicate rows found!')\n",
    "    print('Number of duplicate rows:', duplicateRowsDF.shape[0])\n",
    "    duplicateRowsDF = df[df.duplicated(keep=False)]\n",
    "    duplicateRowsIndices = duplicateRowsDF.index\n",
    "    #duplicateRowsIndices = duplicateRowsDF.groupby(duplicateRowsDF.columns.tolist()).apply(lambda x: tuple(x.index)).tolist()\n",
    "    print('Indices of duplicate rows:')\n",
    "    print(duplicateRowsIndices)\n",
    "    print('Removing duplicate rows except for the first occurrence...')\n",
    "    df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "    print('Done.')\n",
    "    print('After removing duplicates, the table now has', df.shape[0], 'rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Potentially add some more sanity checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2\n",
    "### Remove customers who didn't accept the offer / didn't sign the contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count customers per status\n",
    "print('Checking what customer status is available in the data - overview of potential status codes:')\n",
    "print('5 = zurückgelegt (customer did not accept the offer / did not sign the contract')\n",
    "print('15 = abgelehnt (customer REJECTED)')\n",
    "print('100, 110 = freigeschalten (customer ACCEPTED)')\n",
    "print('75 = ?')\n",
    "sns.countplot(y=\"STATUS_ID\", data=df)\n",
    "plt.show()\n",
    "display(df['STATUS_ID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove status \"5\" customers (status == 5) and ALSO status == 75\n",
    "print('Removing customers with status == 5 and status == 75...')\n",
    "df_relevant = df[~df['STATUS_ID'].isin([5, 75])].copy()\n",
    "\n",
    "# Count customers per status\n",
    "print('Overview of the status codes after removing 5 and 75:')\n",
    "sns.countplot(y=\"STATUS_ID\", data=df_relevant)\n",
    "plt.show()\n",
    "display(df_relevant['STATUS_ID'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3\n",
    "### Remove labels for the rejected customers (critical!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove labels for the rejected customers\n",
    "print('Original number of defaulters and non-defaulters:')\n",
    "display(df_relevant['NEVERPAYER'].value_counts())\n",
    "print('Removing labels for rejected customers...')\n",
    "df_relevant_empty_labels = df_relevant.copy()\n",
    "df_relevant_empty_labels['NEVERPAYER'] = np.where(df_relevant_empty_labels['STATUS_ID']==15, np.nan, df_relevant_empty_labels['NEVERPAYER'])\n",
    "print('Number of defaulters and non-defaulters after ensuring rejected customers have empty label values:')\n",
    "display(df_relevant_empty_labels['NEVERPAYER'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4\n",
    "### Create \"BIRTH_MONTH\" column - based on the \"BIRTHDATE\" column - to support column name and to format known to CRIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_empty_labels['BIRTHDATE'] = pd.to_datetime(df_relevant_empty_labels['BIRTHDATE'])\n",
    "#df['BIRTHDATE'].sort_values(ascending=False).replace('nan', np.nan).head(14270)\n",
    "#df.loc[df['BIRTHDATE'] == '01.07.50']\n",
    "\n",
    "#for index, row in df.iterrows():\n",
    "#   try:\n",
    "#        pd.to_datetime(row['BIRTHDATE'])\n",
    "#    except:\n",
    "#        print(index)\n",
    "#        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_relevant_empty_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating the BIRTH_MONTH column in format YYYY.MM instead of YYYY-MM-DD...')\n",
    "df_relevant_empty_labels['BIRTH_MONTH'] = df_relevant_empty_labels['BIRTHDATE'].map(lambda x: (100*x.year + x.month)/100)\n",
    "print('Done.')\n",
    "print('Overview of first 5 rows including the new BIRTH_MONTH column')\n",
    "display(df_relevant_empty_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5\n",
    "### Add \"TAC\" column - which is not available in the current data, but will be used in the future and is required as an input by CRIF. This column will be filled with a dummy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adding \"TAC\" column and filling it with dummy data...')\n",
    "df_relevant_empty_labels.loc[:, 'TAC'] = '35602508'\n",
    "print('Done.')\n",
    "print('Overview of first 5 rows including the new TAC column')\n",
    "display(df_relevant_empty_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6\n",
    "### Selecting columns which should be used for model training, i.e. are available in CRIF production environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Selecting columns...')\n",
    "df_final_tool_input = df_relevant_empty_labels[['AKZ', # Erweiterung\n",
    "                                               'DEVICE_PRICE', # Erweiterung\n",
    "                                               'MNP_YN', # Erweiterung\n",
    "                                               'COUNTRY', # CRIF\n",
    "                                               'IDENTIFICATION_TYPE', # CRIF\n",
    "                                               #'CNT_NOFEE_OPTIONS', # NOT ON LIST\n",
    "                                               #'INSTALLMENT_TYPE', # NOT ON LIST\n",
    "                                               'ISO', # CRIF\n",
    "                                               #'CNT_FEE_OPTIONS', # NOT ON LIST\n",
    "                                               'BIN', # CRIF\n",
    "                                               'ZIP', # CRIF\n",
    "                                               'GENDER', # CRIF\n",
    "                                               #'KAUTION', # gestrichen\n",
    "                                               'PURCHASE_HOUR', # Erweiterung\n",
    "                                               'BILL_ONLINE_YN', # Erweiterung\n",
    "                                               #'VALUE_NONREC_FEE', # NOT ON LIST\n",
    "                                               'LIABILITY', # Erweiterung\n",
    "                                               'TARIF_FEE', # Erweiterung\n",
    "                                               'PURCHASE_DATE', # Erweiterung - NO PREDICTIVE VALUE IN THIS FORMAT, TOO MANY UNIQUE VALUES\n",
    "                                               'BIRTH_MONTH', # CRIF, TO BE CLARIFIED, format is just the month number\n",
    "                                               #'BIRTHDATE', # NOT ON LIST, TO BE CLARIFIED, format is a full date (not year)\n",
    "                                               'STATUS_ID', # gestrichen, but we keep it for benchmarking purposes\n",
    "                                               'MVD_MONTHS', # Erweiterung\n",
    "                                               #'CNT_INSURANCE', # NOT ON LIST\n",
    "                                               'DEALER_CODE', # CRIF\n",
    "                                               #'VALUE_INSURANCE_FEE', # NOT ON LIST\n",
    "                                               #'SIMLOCK_FLAG', # NOT ON LIST\n",
    "                                               'DEVICE_MODEL_TYPE', # Erweiterung\n",
    "                                               'SEGMENT_TARIF', # Erweiterung\n",
    "                                               'TARIF_ID', # CRIF\n",
    "                                               #'CNT_INTERLOCK', # NOT ON LIST\n",
    "                                               'MEMORY_SIZE', # Erweiterung\n",
    "                                               'VOLLJAEHRIG', # CRIF\n",
    "                                               'AUSWEISVORH', # CRIF\n",
    "                                               'CITY', # CRIF - think about some smart encoding here\n",
    "                                               #'VALUE_RECURRING_FEE', # NOT ON LIST\n",
    "                                               #'CRIF_DECISION', # NOT ON LIST\n",
    "                                               'KLAX_MAX_UMSTEIGER_PRE2POST', # Erweiterung\n",
    "                                               'PAYMENT', # CRIF\n",
    "                                               'DEVICE_INFO', # Erweiterung - consider smart encoding or removing\n",
    "                                               'REDUKTION', # Erweiterung\n",
    "                                               'CRIF_SCORE', # CRIF\n",
    "                                               'CONTRACT_INFO', # Erweiterung\n",
    "                                               'BRAND', # CRIF\n",
    "                                               'DEPOSIT', # Erweiterung\n",
    "                                               'NEVERPAYER', # LABEL\n",
    "                                               'TAC']].copy() # New colunn with dummy data - column required by CRIF\n",
    "\n",
    "print('Done.')\n",
    "print('Final table with only columns that will be used for model training - first five rows:')\n",
    "display(df_final_tool_input.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7\n",
    "### Specifying decision column and label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Specifying decision column and label column...')\n",
    "## Decision column assumed to not exist unless specified by the user\n",
    "decision_column = None\n",
    "label_column = None\n",
    "\n",
    "## User specifies which column is the decision column\n",
    "decision_column = 'STATUS_ID'\n",
    "label_column = 'NEVERPAYER'\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"lean\" dataframe that will be used in next steps\n",
    "#print('Creating lean dataframe including only columns needed for model training and evaluation...')\n",
    "#input_cols.extend(decision_columns)\n",
    "#input_cols.extend([label_column])\n",
    "#df_relevant = df[input_cols].copy()\n",
    "#print('Done.')\n",
    "\n",
    "# TODO: for model retraining, \n",
    "# a cross-check whether column names and dtypes are the same as in the first training should be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing completely empty columns:\n",
    "# Number of missing values per column\n",
    "#print('Checking whether there are empty columns...')\n",
    "#completely_empty_cols = []\n",
    "#for index, value in df.isnull().sum().iteritems():\n",
    "#    if value == df.shape[0]:\n",
    "#        completely_empty_cols.append(index)\n",
    "        \n",
    "#print('Completely empty columns found. They are going to be removed:')\n",
    "#print(completely_empty_cols)\n",
    "#print('Removing empty columns...')\n",
    "#df_relevant.drop(completely_empty_cols, inplace=True, axis=1)\n",
    "#print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df_relevant.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "# PART 2\n",
    "## DATA PREPROCESSING AND MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final_tool_input = df_relevant.copy()\n",
    "print('Overview of the number of defaulters (label = 1) vs good customers (label = 0)')\n",
    "sns.countplot(y=label_column, data=df_final_tool_input)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## STEP 1\n",
    "### Split data into \"model_data\" (to be used for model training and biz case) and \"bc_only_data\" (biz case only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Updated MLB flow - only if decision_column is not None(!). Otherwise standard training as before.\n",
    "\n",
    "## Step 1: Split data into \"model_data\" and \"bc_only_data\"\n",
    "print('Splitting data into \"model_data\" and \"bc_only_data\"...')\n",
    "\n",
    "# model_data == data which has a label (might include some rejected customers)\n",
    "model_data = df_final_tool_input[df_final_tool_input[label_column].notnull()]\n",
    "print('Number of rows in the \"model_data\":', model_data.shape[0])\n",
    "#display(model_data.shape)\n",
    "\n",
    "# bc_only_data == data which has no label (assumed to be only rejected customers)\n",
    "bc_only_data = df_final_tool_input[df_final_tool_input[label_column].isnull()]\n",
    "print('Number of rows in the \"bc_only_data\":', bc_only_data.shape[0])\n",
    "#display(bc_only_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## STEP 2\n",
    "### Split \"model data\" into training and testing set\n",
    "#### NOTE: TEST SET SIZE = 25% OF \"MODEL_DATA\" RECOMMENDED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Train-test split model data\n",
    "print('Splitting \"model_data\" into training and testing set...')\n",
    "train_set, test_set = train_test_split(model_data, test_size=0.25, random_state=42)\n",
    "print('Done.')\n",
    "\n",
    "# At this point we have three data subsets: training data, test data (for evaluating the model),\n",
    "# bc_only data (data without labels, for business case purposes only)\n",
    "# Next, we use the first two subsets to run MLB training and testing - with minor modifications due to decision column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## STEP 3\n",
    "### Upsample the minority class in the training set\n",
    "#### (this step is not appllied to TMA dataset due to its incompatibility with probability calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## Step 3: Upsample the minority class in the training set\n",
    "print('Upsampling the minority class (neverpayers) in the training set...')\n",
    "# Check how many neverpayers and payers we have\n",
    "print('Training set - before upsampling - number of labels 0 and 1:')\n",
    "display(train_set[label_column].value_counts())\n",
    "print()\n",
    "print('Test set:')\n",
    "display(test_set[label_column].value_counts())\n",
    "print()\n",
    "\n",
    "# Separate majority and minority classes\n",
    "train_majority = train_set[train_set[label_column]==0]\n",
    "train_minority = train_set[train_set[label_column]==1]\n",
    " \n",
    "# Upsample minority class\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=train_majority.shape[0],  # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "train_set_upsampled = pd.concat([train_majority, train_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print('Training set - after upsampling:')\n",
    "display(train_set_upsampled[label_column].value_counts())\n",
    "\n",
    "print('Upsampling completed.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## STEP 4\n",
    "### Read in feature types (defined manually here, normally to be specified on the frontend by the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a widget that allows the user to change feature type allocation (not relevant for model retraining)\n",
    "### Step 4 - define feature types - NORMALLY THIS COMES FROM THE FRONTEND\n",
    "print('Specifying feature types...')\n",
    "\n",
    "feature_types_df = pd.DataFrame(index = df_final_tool_input.nunique().index, columns = ['feature_type'])\n",
    "\n",
    "categorical_features = df_final_tool_input.select_dtypes(include=['object']).nunique().index.values\n",
    "numerical_features = df_final_tool_input.select_dtypes(exclude=['object']).nunique().index.values\n",
    "\n",
    "#display(categorical_features)\n",
    "#display(numerical_features)\n",
    "\n",
    "for index in feature_types_df.index.values:\n",
    "    if index in categorical_features:\n",
    "        feature_types_df.loc[index, 'feature_type'] = 'categorical'\n",
    "    elif index in numerical_features:\n",
    "        feature_types_df.loc[index, 'feature_type'] = 'numerical'\n",
    "    else:\n",
    "        print('ERROR')\n",
    "\n",
    "# Drop label_column and decision_column from feature list\n",
    "cols_to_drop = [decision_column, label_column]\n",
    "feature_types_df.drop(cols_to_drop, inplace = True)\n",
    "\n",
    "#display(feature_types_df)\n",
    "#print()\n",
    "\n",
    "## Manually change some of feature types\n",
    "feature_types_df.loc['COUNTRY', 'feature_type'] = 'categorical'\n",
    "feature_types_df.loc['GENDER', 'feature_type'] = 'categorical'\n",
    "feature_types_df.loc['PURCHASE_DATE', 'feature_type'] = 'categorical'\n",
    "feature_types_df.loc['TARIF_ID', 'feature_type'] = 'categorical'\n",
    "feature_types_df.loc['SEGMENT_TARIF', 'feature_type'] = 'categorical'\n",
    "\n",
    "feature_types = feature_types_df.to_dict()['feature_type']\n",
    "#display(feature_types)\n",
    "\n",
    "## Generate a few lists which will be useful later on\n",
    "feature_names_list = list(feature_types.keys())\n",
    "feature_types_list = list(feature_types.values())\n",
    "\n",
    "#display(feature_names_list)\n",
    "#display(feature_types_list)\n",
    "\n",
    "categorical_features = []\n",
    "numerical_features = []\n",
    "categorical_feature_indices = []\n",
    "\n",
    "for feature_index, feature_type in enumerate(feature_types_list):\n",
    "    if feature_type == 'categorical':\n",
    "        categorical_features.append(feature_names_list[feature_index])\n",
    "        categorical_feature_indices.append(feature_index)\n",
    "    else:\n",
    "        numerical_features.append(feature_names_list[feature_index])\n",
    "\n",
    "print('Categorical features:')\n",
    "display(categorical_features)\n",
    "print()\n",
    "print('Numeric features:')\n",
    "display(numerical_features)\n",
    "print('Feature types specified.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIONAL: Generate feature types metadata (to be used in the prediction API later on)\n",
    "#count = 0\n",
    "#features_metadata = []\n",
    "#for index in feature_types_df.index.values:\n",
    "#    features_metadata.append({\n",
    "#        'name': index,\n",
    "#        'type': feature_types_df.loc[index, 'feature_type'],\n",
    "#        'index': count\n",
    "#    })\n",
    "#    count += 1\n",
    "#display(features_metadata)\n",
    "\n",
    "#import json\n",
    "#json_dump = json.dumps(features_metadata)\n",
    "#print(json_dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## STEPS 5, 6, 7\n",
    "### Prepare data for training, fit the pipeline (train model), test the pipeline (evaluate model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 5: Prepare data for training in dataframe format - this is the format from which conversion to a dict is easy\n",
    "print('Splitting the data into features and labels...')\n",
    "\n",
    "# With upsampling:\n",
    "#features_train = train_set_upsampled.drop(cols_to_drop, axis=1)\n",
    "#labels_train = train_set_upsampled[[label_column]]\n",
    "\n",
    "# Without upsampling\n",
    "features_train = train_set.drop(cols_to_drop, axis=1)\n",
    "labels_train = train_set[[label_column]]\n",
    "\n",
    "features_test = test_set.drop(cols_to_drop, axis=1)\n",
    "labels_test = test_set[[label_column]]\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate(pipeline):\n",
    "    ### Step 6: Fit the pipeline\n",
    "    print('Fitting the pipeline (model training)... ')\n",
    "    print('This can take around 20-40 mins on TMA dataset depending on available computing power...')\n",
    "    pipeline.fit(features_train,\n",
    "                labels_train.values.ravel(),\n",
    "                userdtypescasting__feature_types=feature_types_list,\n",
    "                unseenvalueschecker__feature_types=feature_types_list)\n",
    "    print('Pipeline fitting completed.')\n",
    "\n",
    "    ### Step 7: Test the pipeline by making predictions and computing metrics\n",
    "    print('Validating the pipeline (evaluating the model)...')\n",
    "    print('Model evaluation results:')\n",
    "    validate(pipeline, features_test, labels_test)\n",
    "    print('Pipeline validated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Run model training and evaluation - this can take some time\n",
    "# TODO: Consider adding progress / countdown widget / stopclock\n",
    "fit_and_validate(RF_pipeline_uncalibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Run model training and evaluation - this can take some time\n",
    "# TODO: Consider adding progress / countdown widget / stopclock\n",
    "fit_and_validate(RF_pipeline_isotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Run model training and evaluation - this can take some time\n",
    "# TODO: Consider adding progress / countdown widget / stopclock\n",
    "fit_and_validate(RF_pipeline_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot calibration plots\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "for clf, name in [(RF_pipeline_uncalibrated, 'Uncalibrated'),\n",
    "                  (RF_pipeline_isotonic, 'Isotonic calibration'),\n",
    "                  (RF_pipeline_sigmoid, 'Sigmoid calibration')]:\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        prob_pos = clf.predict_proba(features_test)[:, 1]\n",
    "    else:  # use decision function\n",
    "        prob_pos = clf.decision_function(features_test)\n",
    "        prob_pos = \\\n",
    "            (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(labels_test, prob_pos, n_bins=20)\n",
    "\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "             label=\"%s\" % (name, ))\n",
    "\n",
    "    ax2.hist(prob_pos, range=(0, 1), bins=20, label=name,\n",
    "             histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Mean predicted value\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TO JUST COMPARE CALIBRATION RESULTS STOP RUNNING CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_timestamp = '{:%Y-%b-%d_%H:%M:%S}'.format(datetime.datetime.now())\n",
    "print('Model training completed on ', model_training_timestamp,'.')\n",
    "print('Creating dedicated output directory...')\n",
    "dirName = '../output/%s/' % (model_training_timestamp)\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    os.mkdir(dirName+'standalone-deployment')\n",
    "    os.mkdir(dirName+'business-case-data')\n",
    "    print(\"Directory \" , dirName ,  \"successfully created.\")\n",
    "except FileExistsError:\n",
    "    print(\"ERROR: Directory \" , dirName ,  \"already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign generic name \"RF_pipeline\" to selected pipeline\n",
    "# For the initial deployment, the uncalibrated model version was used.\n",
    "# However, in the future, the calibrated version might do a better job\n",
    "RF_pipeline = RF_pipeline_uncalibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Persist model, and model training and validation data\n",
    "# TODO: Make sure old model doesn't get overwritten in case someone is retraining the model\n",
    "print('Saving model and auxiliary data into ', dirName)\n",
    "#joblib.dump(RF_pipeline_uncalibrated, dirName+'standalone-deployment/RF_pipeline_uncalibrated.pkl')\n",
    "#joblib.dump(RF_pipeline_isotonic, dirName+'standalone-deployment/RF_pipeline_isotonic.pkl')\n",
    "joblib.dump(RF_pipeline, dirName+'standalone-deployment/RF_pipeline.pkl')\n",
    "#joblib.dump(features_train, '../output/sample_features_train.pkl')\n",
    "#joblib.dump(labels_train, '../output/sample_labels_train.pkl')\n",
    "#joblib.dump(features_test, '../output/sample_features_test.pkl')\n",
    "#joblib.dump(labels_test, '../output/sample_labels_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read-in model\n",
    "# Uncomment the below code if you want to read in the already saved model\n",
    "#RF_pipeline = joblib.load('../output/2019-Aug-22_21:38:03/standalone-deployment/RF_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## STEP 8\n",
    "### Make probability predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Step 8: Make probability predictions on test data\n",
    "print('Making predictions on test data...')\n",
    "test_set_predictions = RF_pipeline.predict_proba(features_test)[:,1]\n",
    "print('Done.')\n",
    "print('Distribution of predicted probabilities:')\n",
    "sns.violinplot(test_set_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## STEP 9\n",
    "### Make probability predictions on \"bc_only\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 9: Make probability predictions on \"bc_only\" data\n",
    "print('Making predictions on bc_only data...')\n",
    "features_bc_data_only = bc_only_data.drop([label_column], axis=1)\n",
    "print('Done.')\n",
    "print('Distribution of predicted probabilities:')\n",
    "bc_only_data_predictions = RF_pipeline.predict_proba(features_bc_data_only)[:,1]\n",
    "sns.violinplot(bc_only_data_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## STEP 10\n",
    "### Combine predictions with respective original data subsets (i.e. assign samples to predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 10: Combine predictions with respective data subsets\n",
    "print('Combining predictions with test and bc_only datasets...')\n",
    "test_set_with_predictions = test_set.copy()\n",
    "test_set_with_predictions['MLB_PD'] = test_set_predictions\n",
    "#display(test_set_with_predictions.head())\n",
    "\n",
    "bc_only_data_with_predictions = bc_only_data.copy()\n",
    "bc_only_data_with_predictions['MLB_PD'] = bc_only_data_predictions\n",
    "#display(bc_only_data_with_predictions.head())\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## STEP 11\n",
    "### Upsample test set x4 (to be in correct relation to the \"bc_only\" data)\n",
    "#### Note: BASED ON THE ASSUMPTION TEST SET SIZE == 25% MODEL_DATA SIZE (!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 11: Upsample test set x4 (to be in correct relation to the \"bc_only\" data)\n",
    "print('Upsampling test set x4...')\n",
    "print('Size of the test set before upsampling:')\n",
    "display(test_set_with_predictions.shape)\n",
    "test_set_with_predictions_upsampled = test_set_with_predictions.copy()\n",
    "for i in range(3):\n",
    "    test_set_with_predictions_upsampled = test_set_with_predictions_upsampled.append(test_set_with_predictions)\n",
    "\n",
    "print('Size of the test set after upsampling:')\n",
    "display(test_set_with_predictions_upsampled.shape)\n",
    "print('Upsampling completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## STEP 12\n",
    "### Generate final bc data table with probability predictions per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 12: Generate the final table with predictions\n",
    "print('Generating the final bc table...')\n",
    "output_data_upsampled = test_set_with_predictions_upsampled.copy()\n",
    "output_data_upsampled = output_data_upsampled.append(bc_only_data_with_predictions)\n",
    "print('Final bc table - upsampled - table dimensions:')\n",
    "display(output_data_upsampled.shape)\n",
    "print('Final bc table - upsampled - first five rows of data:')\n",
    "display(output_data_upsampled.head())\n",
    "\n",
    "output_data_without_upsampling = test_set_with_predictions.copy()\n",
    "output_data_without_upsampling = output_data_without_upsampling.append(bc_only_data_with_predictions)\n",
    "print('Final bc table - without upsampling - table dimensions:')\n",
    "display(output_data_without_upsampling.shape)\n",
    "print('Final bc table - without upsampling - first five rows of data:')\n",
    "display(output_data_without_upsampling.head())\n",
    "print('Final bc table successfully generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## STEP 13\n",
    "### Save the bc data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 13: Save (output) the created table\n",
    "print('Saving bc table into', dirName,'...')\n",
    "output_data_upsampled.to_csv(dirName+'business-case-data/bc_data_table_upsampled.csv',\n",
    "                             index=True)\n",
    "output_data_without_upsampling.to_csv(dirName+'business-case-data/bc_data_table_without_upsampling.csv',\n",
    "                                      index=True)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## STEP 14\n",
    "### Generate outputs for deployment testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and persist predictions on test features\n",
    "print('Generating and saving downsampled test predictions and test features into', dirName)\n",
    "predictions_test = RF_pipeline.predict_proba(features_test)\n",
    "pred_test = pd.DataFrame(predictions_test, columns=['probability_of_nondefault', 'probability_of_default'])\n",
    "\n",
    "features_test_with_predictions = features_test.copy()\n",
    "features_test_with_predictions['probability_of_nondefault'] = pred_test['probability_of_nondefault'].values\n",
    "features_test_with_predictions['probability_of_default'] = pred_test['probability_of_default'].values\n",
    "\n",
    "features_test_with_predictions_downsampled = resample(features_test_with_predictions, \n",
    "                                                replace=False,     # sample without replacement\n",
    "                                                n_samples=1000,\n",
    "                                                random_state=42) # reproducible results\n",
    "\n",
    "features_test_downsampled = features_test_with_predictions_downsampled.drop(['probability_of_nondefault', 'probability_of_default'], axis=1)\n",
    "pred_test_downsampled = features_test_with_predictions_downsampled[['probability_of_nondefault', 'probability_of_default']]\n",
    "\n",
    "# Persist test features and test labels for future reuse, e.g. model testing prior to deployment\n",
    "\n",
    "features_test_downsampled.to_csv(dirName+'standalone-deployment/test_features.csv', index=False, float_format='%.4f')\n",
    "pred_test_downsampled.to_csv(dirName+'standalone-deployment/test_predictions.csv', index=False, float_format='%.3f')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save categorical values and numeric ranges\n",
    "print('Generating and saving unique values of categorical features and ranges of numeric features into', dirName)\n",
    "categorical_values = {}\n",
    "numeric_ranges = {}\n",
    "\n",
    "for feature_name in categorical_features:\n",
    "    feature_unique_values = features_train[feature_name].unique().tolist()\n",
    "    categorical_values.update({feature_name : feature_unique_values})\n",
    "        \n",
    "for feature_name in numerical_features:\n",
    "    feature_range = [float(features_train.loc[:, feature_name].min()), float(features_train.loc[:, feature_name].max())]\n",
    "    numeric_ranges.update({feature_name : feature_range})\n",
    "\n",
    "with open(dirName+'standalone-deployment/categorical_values.json', 'w') as fp:\n",
    "    json.dump(categorical_values, fp, sort_keys=True, indent=2)\n",
    "with open(dirName+'standalone-deployment/numeric_ranges.json', 'w') as fp:\n",
    "    json.dump(numeric_ranges, fp, sort_keys=True, indent=2)\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copying the latest version of pipeline_components.py into', dirName)\n",
    "print('These module defines custom data transformations and is needed for production deployment.')\n",
    "print('For details, please refer to the deployment manual.')\n",
    "print('...')\n",
    "copyfile('../src/library/pipeline_components.py', dirName+'standalone-deployment/pipeline_components.py')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating and saving required features list into', dirName)\n",
    "required_features = features_train.columns.to_list()\n",
    "\n",
    "with open(dirName+'standalone-deployment/required_features.json', 'w') as fp:\n",
    "    json.dump(required_features, fp, sort_keys=True, indent=2)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating and saving features datatypes into', dirName)\n",
    "features_dtypes = features_train.dtypes.apply(lambda x: x.name).to_dict()\n",
    "#print(features_dtypes)\n",
    "\n",
    "with open(dirName+'standalone-deployment/features_dtypes.json', 'w') as fp:\n",
    "    json.dump(features_dtypes, fp, sort_keys=True, indent=2)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving system type and versions of key dependencies for deployment reference:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "print('Configuration of the system and key dependencies in the environment in which the model was trained:')\n",
    "print()\n",
    "print('Operating system:', platform.system())\n",
    "print('OS release:', platform.release())\n",
    "print('Machine:', platform.machine())\n",
    "print('Platform:', platform.platform())\n",
    "print('Version:', platform.version())\n",
    "print()\n",
    "print('Python version: {}'.format(sys.version))\n",
    "print('Pandas version: {}'.format(pd.__version__))\n",
    "print('Numpy version: {}'.format(np.__version__))\n",
    "print('Scikit-learn version: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirName+'standalone-deployment/system_and_dependencies.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copying the latest version of DEPLOYMENT_HINTS.md into', dirName)\n",
    "copyfile('../DEPLOYMENT_HINTS.md', dirName+'standalone-deployment/DEPLOYMENT_HINTS.md')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copying the latest version of validation_script.py into', dirName)\n",
    "copyfile('../validation_script.py', dirName+'standalone-deployment/validation_script.py')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copying prediction-api files into', dirName)\n",
    "copytree('../prediction-api', dirName+'prediction-api')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate feature types metadata (to be used in the prediction API later on)\n",
    "print('Saving model into ', dirName+'prediction-api/data/model.pkl')\n",
    "joblib.dump(RF_pipeline, dirName+'prediction-api/data/model.pkl')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate feature types metadata (to be used in the prediction API)\n",
    "print('Generating feature types metadata for prediction API and saving them into', dirName+'prediction-api/data')\n",
    "\n",
    "meta_data_dict = {}\n",
    "meta_data_dict['label'] = label_column\n",
    "count = 0\n",
    "\n",
    "features_metadata = []\n",
    "for index in feature_types_df.index.values:\n",
    "    features_metadata.append({\n",
    "        'name': index,\n",
    "        'type': feature_types_df.loc[index, 'feature_type'],\n",
    "        'index': count\n",
    "    })\n",
    "    count += 1\n",
    "\n",
    "meta_data_dict['features'] = features_metadata\n",
    "\n",
    "#display(meta_data_dict)\n",
    "\n",
    "with open(dirName+'prediction-api/data/meta_data.json', 'w') as fp:\n",
    "    json.dump(meta_data_dict, fp, sort_keys=True, indent=2)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving features datatypes into', dirName+'prediction-api/data')\n",
    "\n",
    "with open(dirName+'prediction-api/data/features_dtypes.json', 'w') as fp:\n",
    "    json.dump(features_dtypes, fp, sort_keys=True, indent=2)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate test data for API\n",
    "print('Generating test request and test response for prediction API and saving them into', dirName+'prediction-api/documentation')\n",
    "smoke_test_features = features_test.head(10)\n",
    "#display(smoke_test_features)\n",
    "\n",
    "with open(dirName+'prediction-api/documentation/test_request_body.json', 'w') as fp:\n",
    "    json.dump(smoke_test_features.to_dict(orient='records'),\n",
    "              fp,\n",
    "              sort_keys=True,\n",
    "              indent=2,\n",
    "              default=str)\n",
    "\n",
    "#print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_predictions_array = RF_pipeline.predict_proba(smoke_test_features)\n",
    "smoke_predictions_list = []\n",
    "for index in range(0, smoke_predictions_array.shape[0]):\n",
    "    smoke_predictions_list.append({\n",
    "        'nondefault': {\n",
    "            'probability': smoke_predictions_array[index, 0]\n",
    "        },\n",
    "        'default': {\n",
    "            'probability': smoke_predictions_array[index, 1]\n",
    "        }\n",
    "    })\n",
    "\n",
    "#display(smoke_predictions_list)\n",
    "\n",
    "with open(dirName+'prediction-api/documentation/test_response_body.json', 'w') as fp:\n",
    "    json.dump(smoke_predictions_list, fp, sort_keys=True, indent=2)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copying the latest version of SRC module into', dirName+'prediction-api/modules/src')\n",
    "print('This module defines custom data transformations and is needed for production deployment.')\n",
    "print('...')\n",
    "if os.path.exists(dirName+'prediction-api/modules/src'):\n",
    "    rmtree(dirName+'prediction-api/modules/src')\n",
    "    \n",
    "copytree('../src', dirName+'prediction-api/modules/src')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:credit-scoring-tma]",
   "language": "python",
   "name": "conda-env-credit-scoring-tma-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
